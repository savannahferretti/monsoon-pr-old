{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06bbae7-0b9d-437a-b85a-6656bfd58f51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ef283b-e640-49b7-83cf-422d1e1a93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xgcm import Grid\n",
    "from datetime import datetime\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f70d50-7e58-4010-9868-023ce4f9c1eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## User-Defined Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fb0120-3761-4842-9e2a-d49ce6be9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR   = 'Savannah L. Ferretti'\n",
    "EMAIL    = 'savannah.ferretti@uci.edu'\n",
    "SAVEDIR  = '/ocean/projects/atm200007p/sferrett/Repos/monsoon-pr/data/interim'\n",
    "YEARS    = [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014]\n",
    "MONTHS   = [6,7,8]\n",
    "LATRANGE = (0.,30.) \n",
    "LONRANGE = (50.,90.)\n",
    "LEVS     = [500.,550.,600.,650.,700.,750.,775.,800.,825.,850.,875.,900.,925.,950.,975.,1000.]\n",
    "MODELS  = [\n",
    "    # 'AWI-ESM-1-1-LR',\n",
    "    # 'BCC-CSM2-MR',\n",
    "    # 'CESM2',\n",
    "    # 'CMCC-CM2-SR5',\n",
    "    # 'CMCC-ESM2',\n",
    "    # 'CanESM5',\n",
    "    # 'FGOALS-g3',\n",
    "    # 'GISS-E2-1-G',\n",
    "    # 'IITM-ESM',\n",
    "    # 'MIROC-ES2L',\n",
    "    # 'MIROC6',\n",
    "    # 'MPI-ESM-1-2-HAM',\n",
    "    # 'MPI-ESM1-2-HR',\n",
    "    # 'MPI-ESM1-2-LR',\n",
    "    # 'MRI-ESM2-0',\n",
    "    # 'NESM3',\n",
    "    # 'NorESM2-MM',\n",
    "    # 'SAM0-UNICON',\n",
    "    # 'TaiESM1',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d824cb27-94b7-40a2-a1a4-d77ad92d9085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fc0f4-5ab0-44cb-9b95-303fdcb410e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(subset):\n",
    "    kwargs = {\n",
    "        'aggregate':False,\n",
    "        'zarr_kwargs':{'consolidated':True,'use_cftime':True},\n",
    "        'preprocess':combined_preprocessing}\n",
    "    modeldict = subset.to_dataset_dict(**kwargs)\n",
    "    return modeldict\n",
    "\n",
    "def load(model,varname):\n",
    "    url  = 'https://storage.googleapis.com/cmip6/cmip6-pgf-ingestion-test/catalog/catalog.json'\n",
    "    catalog = intake.open_esm_datastore(url)\n",
    "    query = dict(activity_id='CMIP',\n",
    "                 experiment_id='historical',\n",
    "                 source_id=model,\n",
    "                 table_id='6hrLev',\n",
    "                 variable_id=varname,\n",
    "                 grid_label='gn')\n",
    "    subset = catalog.search(**query)\n",
    "    modeldict = get_data_dict(subset)\n",
    "    for key,ds in modeldict.items():\n",
    "        modeldict[key] = ds\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b35a5af4-47ca-481d-a988-0085c408cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,shape):\n",
    "    if shape == '3D':\n",
    "        dims = ['time','y','x']\n",
    "    elif shape == '4D':\n",
    "        dims = ['time','y','x','lev']\n",
    "    data = data.squeeze()\n",
    "    data = data.drop_dims(set(data.dims)-{*dims}).drop({'lon','lat'})\n",
    "    for dim in dims:\n",
    "        if dim == 'time' and data.coords[dim].dtype.kind != 'M':\n",
    "            data.coords[dim] = data.indexes[dim].to_datetimeindex()\n",
    "        elif dim != 'time':\n",
    "            data.coords[dim] = data.coords[dim].astype(float)\n",
    "    data = data.sortby(dims).transpose(*dims)\n",
    "    data = data.rename({'y':'lat','x':'lon'})\n",
    "    return data\n",
    "\n",
    "def subset(data,years=YEARS,months=MONTHS,latrange=LATRANGE,lonrange=LONRANGE):\n",
    "    data = data.sel(time=(data['time.year'].isin(years)) & (data['time.month'].isin(months)))\n",
    "    data = data.sel(lat=slice(*latrange),lon=slice(*lonrange))\n",
    "    return data\n",
    "\n",
    "def interpolate(data,varname):\n",
    "    levtype = data.lev.attrs['standard_name']\n",
    "    if levtype == 'atmosphere_hybrid_sigma_pressure_coordinate':\n",
    "        if 'p0' in list(data.variables):\n",
    "            p = (data.a*data.p0 + data.b*data.ps)/100\n",
    "        else:\n",
    "            p = (data.ap + data.b*data.ps)/100\n",
    "    elif levtype == 'atmosphere_sigma_coordinate':\n",
    "        p = (data.ptop + data.lev*(data.ps-data.ptop))/100\n",
    "    elif levtype == 'alevel':\n",
    "        p = (-1*data.lev).expand_dims({'time':t.time,'lat':t.lat,'lon':t.lon},(1,2,3))\n",
    "    dims = ['time','lat','lon','lev']\n",
    "    p = p.sortby(dims).transpose(*dims)\n",
    "    vardata = {data[varname].name:([*data[varname].dims],data[varname].data),'p':([*p.dims],p.data)}\n",
    "    coords  = {'time':data.time.data,'lat':data.lat.data,'lon':data.lon.data,'lev':data.lev.data}\n",
    "    data = xr.Dataset(vardata,coords)    \n",
    "    grid = Grid(data,coords={'Z':{'center':'lev'}},periodic=False)\n",
    "    interped = grid.transform(data[varname],'Z',np.array(LEVS),target_data=data.p,method='log',mask_edges=False).rename({'p':'lev'})\n",
    "    if varname == 'ta':\n",
    "        interped.name = 't'\n",
    "    elif varname == 'hus':\n",
    "        interped.name = 'q'\n",
    "    return interped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4746c-d24b-4475-85bb-ee4982d115b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(data,longname,units,model,frequency,author=AUTHOR,email=EMAIL):\n",
    "    varname = data.name\n",
    "    vardata = {data.name:([*data.dims],data.data)}\n",
    "    if 'lev' in data.dims:\n",
    "        coords = {'time':data.time.data,'lat':data.lat.data,'lon':data.lon.data,'lev':data.lev.data}\n",
    "    else:\n",
    "        coords = {'time':data.time.data,'lat':data.lat.data,'lon':data.lon.data}\n",
    "    data = xr.Dataset(vardata,coords)\n",
    "    data[varname].attrs = dict(long_name=longname,units=units)\n",
    "    data.time.attrs = dict(long_name='Time')\n",
    "    data.lat.attrs = dict(long_name='Latitude',units='°N')\n",
    "    data.lon.attrs = dict(long_name='Longitude',units='°E')\n",
    "    if 'lev' in data.dims:\n",
    "        data.lev.attrs = dict(long_name='Pressure level',units='hPa')\n",
    "    data.attrs = dict(source=model,frequency=frequency,\n",
    "                      history=f'Created on {datetime.today().strftime(\"%Y-%m-%d\")} by {author} ({email})')\n",
    "    return data\n",
    "    \n",
    "def save(data,model,savedir=SAVEDIR):\n",
    "    varname = list(data.keys())[0]\n",
    "    return data.compute().to_netcdf(f'{savedir}/{model}_{varname}.nc',mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b247f21-aa0e-4cd3-a9a1-29f74d423993",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Process & Save Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eeff8a8-aa5f-44ac-b53c-70dd40ba09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODELS:\n",
    "\n",
    "    ds = load(model,'hus')\n",
    "    ds = preprocess(ds,shape='4D')\n",
    "    q  = interpolate(ds,varname='hus')\n",
    "    q  = dataset(q,longname='Specific humidity',units='kg/kg',frequency='6-hourly',model=model)\n",
    "    q  = subset(q)\n",
    "    save(q,model)\n",
    "    del ds,q\n",
    "    \n",
    "    ds = load(model,'ta')\n",
    "    ds = preprocess(ds,shape='4D')\n",
    "    t  = interpolate(ds,varname='ta')\n",
    "    t  = dataset(t,longname='Air temperature',units='K',frequency='6-hourly',model=model)\n",
    "    t  = subset(t)\n",
    "    save(t,model)\n",
    "    del t\n",
    "\n",
    "    ps = ds.ps/100\n",
    "    ps = dataset(ps,longname='Surface pressure',units='hPa',frequency='6-hourly',model=model)\n",
    "    ps = subset(ps)\n",
    "    save(ps,model)\n",
    "    del ds,ps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monsoon-pr",
   "language": "python",
   "name": "monsoon-pr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
